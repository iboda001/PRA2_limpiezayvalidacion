---
title: 'Práctica 2: Limpieza y validación de los datos'
author: "Irati Boda Ezeiza - iboda001"
date: "11 de junio de 2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#install.packages("ggplot2", repos = 'http://cran.rstudio.org')
library(ggplot2)
#install.packages("corrplot", repos = 'http://cran.rstudio.org')
install.packages("randomForest", repos = 'http://cran.rstudio.org')
install.packages("pROC", repos = 'http://cran.rstudio.org')

library(corrplot)
library(reshape2)
library(caret)
#library(randomForest)
#library(pROC)
library(car)
```

# Detalles de la actividad

## Presentación

En esta práctica se elabora un caso práctico orientado a aprender a identificar los datos relevantes para un proyecto analítico y usar las herramientas de integración, limpieza, validación y análisis de las mismas. 



## Competencias

En esta práctica se desarrollan las siguientes competencias del \textit{Máster de Data Science}:

* Capacidad de analizar un problema en el nivel de abstracción adecuado a cada situación y aplicar las habilidades y conocimientos adquiridos para abordarlo y resolverlo.

* Capacidad para aplicar las técnicas específicas de tratamiento de datos (integración, transformación, limpieza y validación) para su posterior análisis.


## Objetivos

Los objetivos concretos de esta práctica son:

* Aprender a aplicar los conocimientos adquiridos y su capacidad de resolución de problemas en entornos nuevos o poco conocidos dentro de contextos más amplios o multidisciplinares.
* Saber identificar los datos relevantes y los tratamientos necesarios (integración, limpieza y validación) para llevar a cabo un proyecto analítico.
* Aprender a analizar los datos adecuadamente para abordar la información contenida en los datos.
* Identificar la mejor representación de los resultados para aportar conclusiones sobre el problema planteado en el proceso analítico.
* Actuar con los principios éticos y legales relacionados con la manipulación de datos en función del ámbito de aplicación.
* Desarrollar las habilidades de aprendizaje que les permitan continuar

\newpage 

# RESOLUCIÓN

*El dataset, el código y el informe generado están disponibles [este enlace de github](https://github.com/iboda001/PRA2_limpiezayvalidacion).*

Siguiendo las principales etapas de un proyecto analítico, las diferentes tareas a realizar (y justificar) son las siguientes:

## 1. Descripción del dataset 


El dataset escogido ha sido "Breast Cancer Wisconsin (Diagnostic) Data Set" disponible en kaggle en [este enlace](https://www.kaggle.com/uciml/breast-cancer-wisconsin-data/data). Dicho dataset es un conjunto de datos que incluye características de masas mamarias malignas como benignas obtenidos mediante imágenes digitalizadas. Está compuesto por un total de 569 muestras y sus respectivas 32 características (columnas) descritas a continuación: 

* **id**: Número identificativo. *Tipo de dato: Numérico*.
* **diagnosis**: Diagnóstico (M = maligno, B = benigno). *Tipo de dato:Booleano*

Las siguientes características describen las características de los núcleos celulares presentes en la imagen:



* **radius_mean**: Media de las distancias entre en centro y el perímetro. *Tipo de dato: Numérico*.
* **radius_se**: Error estándar de las distancias entre en centro y el perímetro. *Tipo de dato: Numérico*.
* **radius_worst**: "Peor" o mayor valor medio de las distancias entre en centro y el perímetro. *Tipo de dato: Numérico*.

* **texture_mean**: Media de valores de la escala de grises. *Tipo de dato: Numérico*.
* **texture_se**: Error estándar de valores de la escala de grises. *Tipo de dato: Numérico*.
* **texture_worst**: "Peor" o mayor valor medio de valores de la escala de grises. *Tipo de dato: Numérico*.

* **perimeter_mean**: Media del perímetro. *Tipo de dato: Numérico*.
* **perimeter_se**: Error estándar del perímetro. *Tipo de dato: Numérico*.
* **perimeter_worst**: "Peor" o mayor valor medio del perímetro. *Tipo de dato: Numérico*.

* **area_mean**: Media del área *Tipo de dato: Numérico*.
* **area_se**: Error estándar del área *Tipo de dato: Numérico*.
* **area_worst**: "Peor" o mayor valor medio del área *Tipo de dato: Numérico*.

* **smoothness_mean**: Media de la variación local de longitudes de radio.*Tipo de dato: Numérico*.
* **smoothness_se**: Error estándar de la variación local de longitudes de radio.*Tipo de dato: Numérico*.
* **smoothness_worst**: "Peor" o mayor valor medio de la variación local de longitudes de radio.*Tipo de dato: Numérico*.

* **compactness_mean**: Media del perímetro al cuadrado partido entre el área - 1.  *Tipo de dato: Numérico*.
* **compactness_se**: Error estándar del perímetro al cuadrado partido entre el área - 1.  *Tipo de dato: Numérico*.
* **compactness_worst**: "Peor" o mayor valor medio del perímetro al cuadrado partido entre el área - 1.  *Tipo de dato: Numérico*.

* **concavity_mean**: Media de severidad de porciones cóncavas del contorno *Tipo de dato: Numérico*.
* **concavity_se**: Error estándar de severidad de porciones cóncavas del contorno *Tipo de dato: Numérico*.
* **concavity_worst**: "Peor" o mayor valor medio de severidad de porciones cóncavas del contorno *Tipo de dato: Numérico*.

* **concave points_mean**: Media del número de proporciones cóncavas del contorno. *Tipo de dato: Numérico*.
* **concave points_se**: Error estándar del número de proporciones cóncavas del contorno. *Tipo de dato: Numérico*.
* **concave points_worst**: "Peor" o mayor valor medio del número de proporciones cóncavas del contorno. *Tipo de dato: Numérico*.

* **symmetry_mean**: Media de simetría. *Tipo de dato: Numérico*.
* **symmetry_se**: Error estándar de simetría. *Tipo de dato: Numérico*.
* **symmetry_worst**: "Peor" o mayor valor medio de simetría. *Tipo de dato: Numérico*.

* **fractal_dimension_mean**: Media de la "aproximación costera" - 1. *Tipo de dato: Numérico*
* **fractal_dimension_se**: Error estándar de la "aproximación costera" - 1. *Tipo de dato: Numérico*
* **fractal_dimension_worst**: "Peor" o mayor valor medio de la "aproximación costera" - 1. *Tipo de dato: Numérico*



Este dataset es de gran interés tanto para comunidad científica como para los pacientes y futuros pacientes. Para los primeros, hablamos de una base de datos real y de alta, de la que además se disponen de otras dos bases de datos complementarias: [Breast Cancer Wisconsin (Origiginal)](https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/) y [Breast Cancer Wisconsin (Prognostic)](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Prognostic%29). Son muchos los trabajos científicos realizados con este dataset, tanto de machine learning (árboles de decisión, redes neuronales) como de imaging (visualización y localización de la evolución del tumor).

En el caso que nos ocupa, el **objetivo** es construir un clasificador de que sea capaz de reconocer si la masa mamaria es maligna o benigna basándose en las características.  



## 2. Integración y selección de los datos de interés a analizar.

El dataset está compuesto por un solo archivo delimitado por comas (csv). Por lo tanto, comenzaremos con la lectura de dicho fichero mediante la función $read.csv()$ y comprobaremos que la carga se ha realizado correctamente imprimiendo las primeras filas y columnas.

```{r path, include=FALSE}
#Directorio
path="C:\\Users\\Irati\\Documents\\Unibertsitatea\\UOC\\SEMESTRE II\\TIPOLOGÍA Y CICLO DE VIDA DE LOS DATOS\\PRA2\\data\\raw"
```

```{r carga de datos}
#Carga de datos
setwd(path)
data=read.csv(file="data.csv")
old.data<-data[,-ncol(data)]
head(data[,1:6])
```

\newpage

Además, es de nuestro interés analizar si los tipos de datos asignados automáticamente coinciden con los descritos en el apartado anterior:
 
 
```{r tipo-dato}
#Tipo de dato
tipo.variable <- sapply(data,class)
knitr::kable(data.frame(variables=names(tipo.variable),clase=as.vector(tipo.variable)))
```

Observamos que los tipos de datos asignados automáticamente por R se corresponden con la realidad, aunque aparece una última variable $X$ que deberá ser eliminada en el próximo apartado.

\newpage

## 3. Limpieza de los datos.

### 3.1. Ceros y elementos vacíos

Los valores nulos o ceros, entendiendo estos últimos como indicador de ausencia de valores, pueden resultar ser un problema de gran importancia en las bases de datos. Las razones de su existencia suelen ser de distinta índole: errores manuales, errores técnicos, mediciones incorrectas o incluso de manipulación intencionada.  Para garantizar la calidad de nuestro análisis, es imprescindible examinar la existencia de estos, y si la hubiera, tomar la decisión bien de eliminarlos o de imputarlos mediante alguno de los métodos recomendados. En cualesquiera de los casos citados, la manipulación de los datos originales deberá ser citado y justificado.


```{r ceros-NAs}
#Ceros y elementos vacíos
na.count <-sapply(data, function(x) sum((is.na(x))))
na.count
```

Observamos que ninguna de las variables contiene valores vacíos excepto la variable $X$ que está totalmente vacía. Por lo tanto, procederemos a eliminar la característica $X$.

```{r eliminar-X}
#Eliminamos la columna vacía "X"
data=data[,!colnames(data)=="X"]
attach(data)
```

### 3.2. Identificación y tratamiento de valores extremos.

Los valores extremos o *outliers*, son aquellas observaciones que son numéricamente distantes del resto de los datos. Por lo tanto, son sospechosos de no pertenecer al conjunto de datos de donde proceden. Identificaremos los valores extremos de nuestro conjunto de datos con la función $boxplot.stats(x)\$out$ de $R$, y las graficaremos mediante diagramas de cajas.


```{r outliers}
#Valores extremos (outliers)
numeric.data <- data[,c(-1,-2)]

for(i in 1:length(numeric.data) ) {
  cat('Outliers de la variable "',names(numeric.data)[i],'" :\n')
  print(boxplot.stats(numeric.data[,i])$out)
}
```

Podemos apreciar que disponemos de bastantes *outliers*. De los cuales destacamos los dos valores de *radius_se* que parecen ser los que más notablemente difieren del resto. Una vez analizados estos datos, todos ellos parecen ser valores que pertenecen a la realidad, es decir, son valores anómalos pero no erróneos. Se decide mantener todos los datos pero en un proyecto real, será recomendable consultar al oncólogo especialista sobre estos detalles.

Como se ha mencionado anteriormente, graficaremos las distribuciones de las características así como sus outliers. Para ello, y con el fin de que los diagramas de cajas sean más fácil de interpretar, se han agrupado las variables según su rango de valores.


```{r cálculo-medianas}
#Cálculo de mediana de cada variable
median.n <- as.vector(sapply(numeric.data,median,na.rm=TRUE)) 
print(median.n)
```



```{r distribucion-variables}
#Agrupación de valores según rango de valores
var.e01.1<-numeric.data[,c(13,2)]
var.e01.2<-numeric.data[,c(1,21,22)]
var.e02<-numeric.data[,c(4,24)]
var.min1.1<-numeric.data[,c(9,11,25,20)]
var.min1.2<-numeric.data[,c(26,27,29)]
var.min2.1<-numeric.data[,c(5,6,7,8)]
var.min2.2<-numeric.data[,c(10,15,16,17)]
var.min2.3<-numeric.data[,c(18,28,30)]
var.00<-numeric.data[,12]
var.min3<-numeric.data[,c(14,23,3)]
```



```{r boxplot,fig.width=8, fig.height=2}
#Visualización de valores extremos (outliers)
ggplot(stack(var.e01.1), aes(x = ind, y = values))+geom_boxplot()+xlab("")+ylab("")
ggplot(stack(var.e01.2), aes(x = ind, y = values))+geom_boxplot()+xlab("")+ylab("")
ggplot(stack(var.e02), aes(x = ind, y = values))+geom_boxplot()+xlab("")+ylab("")
ggplot(stack(var.min1.1), aes(x = ind, y = values))+geom_boxplot()+xlab("")+ylab("")
ggplot(stack(var.min1.2), aes(x = ind, y = values))+geom_boxplot()+xlab("")+ylab("")
ggplot(stack(var.min2.1), aes(x = ind, y = values))+geom_boxplot()+xlab("")+ylab("")
ggplot(numeric.data, aes(x= "", y = numeric.data[,12])) +geom_boxplot()+xlab("")+ylab("")
ggplot(stack(var.min3), aes(x = ind, y = values))+geom_boxplot()+xlab("")+ylab("")

```

Tras finalizar el proceso de carga, validación y limpieza de datos, guardaremos los datos resultantes en el archivo $data.csv$ en la carpeta *data/processed*.

```{r guardar-archivo-preprocesado}
#Guardamos los datos preprocesados
write.csv(data,"./data/processed/data.csv")
```

\newpage

## 4. Análisis de los datos.

Nuestro principal objetivo es construir un modelo que pueda predecir si un tumor es benigno o maligno según sus características. Para ello, deberemos analizar las características e intentar comprender cuáles tienen valor predictivo.

### 4.1. Selección de los grupos de datos que se quieren analizar/comparar.


Solamente eliminaremos la identificación $id$ y la última caracteristica $X$ que contenía solo valores nulos. La variable $diagnostic$ la utilizaremos como factor de grupo. 

Antes de proseguir con la comprobación de la normalidad y homogeneidad de la varianza, conviene analizar brevemente la variable que utilizaremos como factor de grupo:

```{r table-diagnosis}
#Número de casos benignos vs malignos
data=data[,!colnames(data)=="id"]
attach(data)
diagnostic <- plyr::count(data$diagnosis)
print(sprintf("Maligno: %d | Benigno: %d",diagnostic$freq[2],diagnostic$freq[1]))
```

```{r porcentaje-malignos-benignos}
#Porcentaje de casos malignos
print(sprintf(
  "Porcentaje de tumores malignos: %.2f%%",round(diagnostic$freq[2]/nrow(data)*100,2)
  ))
```

Tratándose de una base de datos cuyo principal interés es identificar aquellos tumores malignos, el porcentaje de tumores malignos es sorprendentemente bajo. El conjunto de datos no representa en este caso una distribución típica de análisis médico,dispondría de un número elevado de tumores malignos frente a un número algo menor de tumores benignos. 


### 4.2. Comprobación de la normalidad y homogeneidad de la varianza.

#### Normalidad

Para contrastar que los valores que toman nuestras variables cuantitativas provienen de una población distribuida normalmente, aplicaremos el test de Shapiro Wilk en cada variables numérica. Para un nivel de significación prefijado a $\alpha=0.05$, en el caso de que el p-valor obtenido sea mayor a dicho valor, rechazaremos la hipótesis nula de que la población sigue una distribución normal. 



```{r normality}

for(i in 1:length(numeric.data) ) {
  if (shapiro.test(numeric.data[,i])$p.value<0.05){
  cat('\nRechazamos la hipótesis nula para la variable numérica ',names(numeric.data)[i])
  }
  else{
  cat('\nNo rechazamos la hipótesis nula para la variable numérica', names(numeric.data)[i])
  }
}
```

Como era de esperar con presencia de tantos outliers, rechazamos la hipótesis nula para todas las variables. 

#### Homogeneidad de la varianza


Para analizar la homogeneidad de las varianzas respecto al tipo de tumor (maligno/benigno) y teniendo en cuenta que hemos rechazado la hipótesis de que las variables siguen una distribución normal, las dos opciones más adecuadas son el test de Levene o el test Fligner-Killeen. Trabajaremos con este último en el que la hipótesis nula es que las dos varianzas son iguales. Así, para los p-valores superiores a un nivel de significación prefijado a $\alpha=0.05$, en el caso de que el p-valor obtenido sea mayor a dicho valor, rechazaremos la hipótesis nula de que las varianzas sean iguales.


```{r fligner.test}

for(i in 3:ncol(data)-1 ) {
  if (fligner.test(data[,i]~diagnosis,data=data)$p.value<0.05){
  cat('\nRechazamos la hipótesis de que las varianzas de ambas 
      muestras sean homogéneas ',names(data)[i])
  }
  else{
  cat('\nNo rechazamos la hipótesis de que las varianzas de ambas
      muestras sean homogéneas', names(data)[i])
  }
}
```






### 4.3. Aplicación de pruebas estadísticas para comparar los grupos de datos.

En función de los datos y el objetivo del estudio, aplicar pruebas de contraste
de hipótesis, correlaciones, regresiones, etc.

#### ¿Existe correlación entre las variables?



```{r correlation,fig.height=8,fig.width=10}

numeric.data$diagnosis <- as.integer(factor(data$diagnosis))-1

correlations <- cor(numeric.data,method="pearson")

corrplot(correlations, number.cex = .9, method = "square", 
         hclust.method = "ward", order = "FPC",
         type = "lower", tl.cex=0.8,tl.col = "black")
```






Las variables más correladas (aquellas con tonalidad más oscura) son: $area\_worst$ y $radius\_worst$; $perimeter\_mean$ y $radius\_worst$; $perimeter\_worst$ y $radius\_worst$; $perimeter\_mean$, $area\_worst$, $area\_mean$ y $radius\_mean$ y, por último, $texture\_mean$ y $texture\_worst$.


#### ¿Qué variables son las que influyen en mayor medida en la malignidad/benignidad de los datos?


Una vez que hemos analizado qué variables tienen mayor correlación entre ellas, estudiaremos cuáles de ellas ejercen una mayor influencia sobre la malignidad/benignidad del tumor. Comenzaremos graficando boxplots y funciones de densidad de las caracteristicas diferenciando tumores malignos vs benignos con el fin de detectar cuáles presentan una diferencia mayor:



```{r boxplot-by-group,fig.width=8, fig.height=2}
#Visualización de valores extremos (outliers) por grupos
mm<-melt(old.data, id=c('id','diagnosis'))
ggplot(mm[c(1:4552),])+geom_boxplot(aes(x=diagnosis, y=value))+facet_grid(.~variable)
ggplot(mm[c(4553:8535),])+geom_boxplot(aes(x=diagnosis, y=value))+facet_grid(.~variable)
ggplot(mm[c(8536:13656),])+geom_boxplot(aes(x=diagnosis, y=value))+facet_grid(.~variable)
ggplot(mm[c(13657:17070),])+geom_boxplot(aes(x=diagnosis, y=value))+facet_grid(.~variable)
```
```{r distribuciones,fig.width=10, fig.height=10}
featurePlot(x=old.data[,c(3:32)], y=old.data[,2], plot="density",
            scales = list(x = list(relation="free"), y = list(relation="free"),cex=0.8),
            layout = c(3,10), auto.key = list(columns = 2), pch = "|")
```



No observamos ninguna variable perfectamente separada pero destacamos que tenemos separaciones bastante buenas para las siguientes características: $concavo.points\_worst$, $concavity\_worst$, $perimeter\_worst$, $area\_mean$ y $perimeter_mean$. También tenemos superposición ajustada para algunos de los valores, como $simetry\_se$, $smoothness_se$. 



#### Construcción del modelo predictivo 

Dadas las características de nuestro dataset, el modelo predictivo escogido ha sido Random Forest (bosque de árboles). Esta, es una técnica de agregación que mejora la precisión en la clasificación mediante la incorporación de aleatoriedad en la construcción de cada clasificador individual. Construiremos un bosque de 100 árboles y entrenaremos el modelo con una partición del dataset original para así poder testearlo con el dataset restante (80%-20%).

``` {r randomForest}
numeric.data <- old.data[,2:32]
numeric.data$diagnosis = as.integer(factor(numeric.data $diagnosis))-1
set.seed(314)
#Separamos el conjunto de datos en un conjunto de entrenamiento y test
training.index <- sample(1:nrow(numeric.data), 0.8 * nrow(numeric.data))
training.data = numeric.data[training.index,]
test.data = numeric.data[-training.index,]
random.forest<-randomForest::randomForest(diagnosis ~ ., data=training.data,ntree=100,
                                          keep.forest=TRUE, importance=TRUE)
variable.importance <- data.frame(random.forest$importance)

ggplot(variable.importance, 
       aes(x=reorder(rownames(variable.importance),X.IncMSE), y=X.IncMSE)) + geom_bar(stat="identity", fill="darkolivegreen", colour="black") +
coord_flip() + theme_bw(base_size = 8) +
  labs(title="Prediction using RandomForest with 100 trees")+ylab("")+xlab("")
```

Las características más importantes son $perimeter\_worst$,$concave.points\_worst$, $area\_worst$, $radius\_worst$,$concave.points\_mean$, $area\_mean$, $concavity\_mean$ y $concavity_worst$ respectivamente.


```{r predicciones}
library(pROC)
breast.pred <- predict(random.forest,test.data)

print(sprintf("Area under curve (AUC) : %.3f",auc(test.data$diagnosis, breast.pred)))
```
Obtenemos un AUC muy alto, lo cual es realmente satisfactorio ya que el AUC es la probabilidad de que, tomados un caso positivo y uno negativo al azar, el scoring del modelo para el primero sea superior al segundo.


## 5. Resolución del problema. A partir de los resultados obtenidos.



Tras el exhaustivo análisis del dataset, la limpieza, la validación y la construcción del árbol, concluímos que las características más importantes son $perimeter\_worst$,$concave.points\_worst$, $area\_worst$, $radius\_worst$,$concave.points\_mean$, $area\_mean$, $concavity\_mean$ y $concavity_worst$ respectivamente. Además, afirmamos que hemos podido construir un modelo capaz de predecir la malignidad/benignidad del tumor con una exactitud muy satisfactoria.



## 7. Código: Hay que adjuntar el código, preferiblemente en R, con el que se ha realizado la limpieza, análisis y representación de los datos. Si lo preferís, también podéis trabajar en Python.

El código en R esta incluido en este fichero con extensión rmd y tambien se puede descargar en GitHub desde la siguiente dirección:

https://github.com/iboda001/PRA2_limpiezayvalidacion/blob/master/Codigo/LimpiezaValidacion.R